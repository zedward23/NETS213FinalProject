# -*- coding: utf-8 -*-
"""NETS213 Final Project Reddit Scraper

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zu8XGgmtylFQusaRHKUryrX6zBv3-KSf
"""

pip install praw

import praw
import pandas as pd
import numpy as np

user_agent = "WallStreetScrapes v1 by /u/scraperSupreme"
reddit = praw.Reddit(
    client_id="eaGL1Ft_TPajuw",
    client_secret="UTM0y2n8IhCFFZ_umjVh4Gs7bAiMNw",
    user_agent=user_agent
)

from praw.models import MoreComments

ddUrl = "https://www.reddit.com/r/wallstreetbets/comments/mtk7tt/what_are_your_moves_tomorrow_april_19_2021/"
ddThread = reddit.submission(url=ddUrl)

data = pd.DataFrame(columns = ['stock', 'comment', 'score'])

numberOfComments = 400
for i in range(numberOfComments):
  if isinstance(ddThread.comments[i], MoreComments):
    break
  data.at[i, 'comment'] = ddThread.comments[i].body
  data.at[i, 'score'] = ddThread.comments[i].score

  stockNames = ["MSFT","AMD","TSM","AMC","CLOV","RKT","SPY","PTON","PLTR","GME","AAPL","MSFT","AMZN","GOOG","GOOGL","FB","TSLA","NVDA","PYPL","ASML","INTC","CMCSA","ADBE","NFLX","CSCO","PEP","AVGO","TXN","PDD","TMUS","COST","QCOM","AMGN"]
  data.at[i, 'stock'] = "stock"
  for stockName in stockNames:
    if stockName.lower() in ddThread.comments[i].body.lower():
      data.at[i, 'stock'] = stockName.upper()
      data.at[i, 'comment'] = ddThread.comments[i].body.lower().replace(stockName.lower(), "[stockName]")

data.to_csv('output1.csv', index=False)

# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also
#   display(data)

# delete when done. for reference

headlines = set()
for sub in reddit.subreddit('WallStreetBets').hot(limit=None):
  print(sub.title)
  print(sub.id)
  print(sub.author)
  print(sub.created_utc)
  print(sub.score)
  print(sub.upvote_ratio)
  print(sub.url)
  break
  headlines.add(sub.title)
print(len(headlines))